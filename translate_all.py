from google import genai
from google.genai import types
import cloudscraper
import requests
from bs4 import BeautifulSoup
import time
import os
import re
import random
from urllib.parse import urljoin

# ==========================================
# ‚öôÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
# ==========================================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") 
DISCORD_WEBHOOK_URL = os.getenv("WEBHOOK_NOVEL_2")
NOVEL_MAIN_URL = "https://kakuyomu.jp/works/16816700429097793676"
DB_FILE = "last_ep_novel_2.txt" 

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Client
if GEMINI_API_KEY:
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
    except Exception as e:
        print(f"‚ùå Error initializing Client: {e}")
        client = None
else:
    print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY")
    client = None

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Scraper
scraper = cloudscraper.create_scraper(
    browser={'browser': 'chrome', 'platform': 'windows', 'desktop': True}
)

# ==========================================
# üõ†Ô∏è ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
# ==========================================

def get_first_episode_url():
    """‡∏´‡∏≤‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1 ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å"""
    print(f"üìñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å‡∏à‡∏≤‡∏Å: {NOVEL_MAIN_URL}")
    try:
        response = scraper.get(NOVEL_MAIN_URL)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏° "‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å"
        first_ep_link = soup.select_one('a#readFromFirstEpisode')
        
        if first_ep_link:
            href = first_ep_link['href']
            full_link = urljoin(NOVEL_MAIN_URL, href)
            print(f"‚úÖ ‡πÄ‡∏à‡∏≠‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å (‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á): {full_link}")
            return full_link
        else:
            # ‡∏™‡∏≥‡∏£‡∏≠‡∏á: ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÉ‡∏ô‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏™‡∏∏‡∏î
            target_pattern = re.compile(r'/works/\d+/episodes/\d+')
            links = soup.find_all('a', href=target_pattern)
            if links:
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏≠‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏î‡πâ‡∏≤‡∏ô)
                # ‡∏õ‡∏Å‡∏ï‡∏¥ Kakuyomu ‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡∏≠‡∏ô ID ‡∏ô‡πâ‡∏≠‡∏¢ = ‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å
                sorted_links = sorted(links, key=lambda x: int(re.search(r'episodes/(\d+)', x['href']).group(1)))
                href = sorted_links[0]['href']
                full_link = urljoin(NOVEL_MAIN_URL, href)
                print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏•‡∏±‡∏Å ‡πÅ‡∏ï‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏ô‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç: {full_link}")
                return full_link
                
        print("‚ùå ‡∏´‡∏≤‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡∏≠‡∏ô‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢")
        return None
    except Exception as e:
        print(f"‚ùå Error getting first episode: {e}")
        return None

def find_next_link(soup, current_url):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏° Next ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ (‡∏´‡∏≤‡∏ó‡∏∏‡∏Å‡∏ã‡∏≠‡∏Å‡∏ó‡∏∏‡∏Å‡∏°‡∏∏‡∏°)"""
    next_link = None
    
    # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏°‡∏•‡∏π‡∏Å‡∏®‡∏£‡∏Ç‡∏ß‡∏≤ (‡∏õ‡∏Å‡∏ï‡∏¥)
    next_btn = soup.select_one('a.widget-episode-navigation-next')
    
    # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏°‡πÉ‡∏´‡∏ç‡πà "‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ" (id="contentMain-readNextEpisode")
    if not next_btn:
        next_btn = soup.select_one('a#contentMain-readNextEpisode')
        
    # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 3: ‡∏´‡∏≤‡∏à‡∏≤‡∏Å Text ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ "Ê¨°„ÅÆ„Ç®„Éî„ÇΩ„Éº„Éâ" (‡πÄ‡∏ú‡∏∑‡πà‡∏≠ Class ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô)
    if not next_btn:
        next_btn = soup.find('a', string=re.compile('Ê¨°„ÅÆ„Ç®„Éî„ÇΩ„Éº„Éâ'))
        
    if next_btn:
        try:
            return urljoin(current_url, next_btn['href'])
        except:
            return None
            
    return None

def get_content_and_next_link(url, max_retries=3):
    headers = {'Referer': NOVEL_MAIN_URL}
    
    for attempt in range(max_retries):
        try:
            time.sleep(random.uniform(2, 4))
            response = scraper.get(url, headers=headers, timeout=20)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                title_elem = soup.select_one('.widget-episodeTitle')
                title = title_elem.text.strip() if title_elem else "Unknown Title"
                
                body = soup.select_one('.widget-episodeBody')
                content = body.get_text(separator="\n", strip=True) if body else None
                
                # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏´‡∏≤‡∏õ‡∏∏‡πà‡∏° Next
                next_link = find_next_link(soup, url)
                
                if content:
                    return {
                        "title": title,
                        "content": content,
                        "next_link": next_link
                    }
                else:
                    # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÄ‡∏ã‡∏ü HTML ‡∏°‡∏≤‡∏î‡∏π (Debug)
                    if attempt == max_retries - 1:
                        with open("debug_error.html", "w", encoding="utf-8") as f:
                            f.write(response.text)
                        print("‚ö†Ô∏è ‡∏´‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å debug_error.html ‡πÅ‡∏•‡πâ‡∏ß)")

            print(f"   ‚ö†Ô∏è ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt+1} ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (Status: {response.status_code})")
        except Exception as e:
            print(f"   ‚ö†Ô∏è Error: {e}")
            
    return None

def translate(text):
    if not text or not client: return None
    
    prompt = f"""
    ‡πÅ‡∏õ‡∏•‡∏ô‡∏¥‡∏¢‡∏≤‡∏¢‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ó‡∏¢ ‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏¢‡∏£‡∏∏‡πà‡∏ô ‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏ô‡∏∏‡∏Å:
    - ‡πÄ‡∏à‡∏≠‡∏â‡∏≤‡∏Å‡∏ß‡∏π‡∏ö‡∏ß‡∏≤‡∏ö‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏ô‡∏ß‡∏ô‡πÉ‡∏´‡πâ‡∏ã‡∏≠‡∏ü‡∏ï‡πå‡∏•‡∏á (‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á)
    - ‡∏´‡πâ‡∏≤‡∏°‡∏´‡∏¢‡∏∏‡∏î‡πÅ‡∏õ‡∏• ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏à‡∏ô‡∏à‡∏ö
    
    ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤:
    {text[:15000]} 
    """ 
    try:
        response = client.models.generate_content(
            model='gemini-1.5-flash', 
            contents=prompt,
            config=types.GenerateContentConfig(
                safety_settings=[
                    types.SafetySetting(category='HARM_CATEGORY_HARASSMENT', threshold='BLOCK_NONE'),
                    types.SafetySetting(category='HARM_CATEGORY_HATE_SPEECH', threshold='BLOCK_NONE'),
                    types.SafetySetting(category='HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold='BLOCK_NONE'),
                    types.SafetySetting(category='HARM_CATEGORY_DANGEROUS_CONTENT', threshold='BLOCK_NONE')
                ]
            )
        )
        return response.text
    except Exception as e:
        print(f"   ‚ùå Gemini Error: {e}")
        return None

def send_discord(ep_num, title, link, content):
    if not DISCORD_WEBHOOK_URL: return
    
    requests.post(DISCORD_WEBHOOK_URL, json={
        "content": f"üìö **[‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà {ep_num}] {title}**\nüîó {link}\n*(‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•...)*"
    })
    
    chunk_size = 1900
    chunks = [content[i:i+chunk_size] for i in range(0, len(content), chunk_size)]
    for i, chunk in enumerate(chunks):
        msg = f"**[{i+1}/{len(chunks)}]**\n{chunk}" if len(chunks) > 1 else chunk
        requests.post(DISCORD_WEBHOOK_URL, json={"content": msg})
        time.sleep(1)
    
    requests.post(DISCORD_WEBHOOK_URL, json={"content": f"‚úÖ **‡∏à‡∏ö‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà {ep_num}**"})

def send_discord_error(ep_num, url, msg):
    if not DISCORD_WEBHOOK_URL: return
    requests.post(DISCORD_WEBHOOK_URL, json={
        "content": f"‚ö†Ô∏è **[‡∏Ç‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà {ep_num}]** {msg}\nüîó {url}"
    })

# ==========================================
# üöÄ Main Loop
# ==========================================

def main():
    print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏õ‡∏•‡πÅ‡∏ö‡∏ö‡∏•‡∏π‡∏Å‡πÇ‡∏ã‡πà (V.5 - Super Finder)...")
    
    current_url = get_first_episode_url()
    if not current_url:
        return

    ep_count = 1
    
    while current_url:
        print(f"\n[{ep_count}] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏•‡∏¥‡∏á‡∏Å‡πå: {current_url}")
        
        data = get_content_and_next_link(current_url)
        
        if not data:
            print("   ‚ùå ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
            send_discord_error(ep_count, current_url, "‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
            break

        title = data['title']
        content = data['content']
        next_link = data['next_link']
        
        print(f"   üìñ ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á: {title}")
        
        # Log ‡∏ß‡πà‡∏≤‡πÄ‡∏à‡∏≠‡∏ï‡∏≠‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÑ‡∏´‡∏°
        if next_link:
            print(f"   üîó ‡πÄ‡∏à‡∏≠‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ: {next_link}")
        else:
            print(f"   ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏õ‡∏∏‡πà‡∏° Next (‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≠‡∏ô‡∏à‡∏ö)")

        print("   ‚è≥ ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤...")
        translated = translate(content)
        
        if translated:
            print("   üöÄ ‡∏™‡πà‡∏á Discord...")
            send_discord(ep_count, title, current_url, translated)
            with open(DB_FILE, "w") as f:
                f.write(current_url)
        else:
            print("   ‚ùå ‡πÅ‡∏õ‡∏•‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô -> ‡∏Ç‡πâ‡∏≤‡∏°")
            send_discord_error(ep_count, current_url, "Gemini ‡πÅ‡∏õ‡∏•‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô")

        if next_link:
            print(f"   ‚û°Ô∏è ‡πÑ‡∏õ‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ... (‡∏£‡∏≠ 30 ‡∏ß‡∏¥)")
            current_url = next_link
            ep_count += 1
            time.sleep(30)
        else:
            print("\nüèÅ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)")
            current_url = None

    print("\nüéâ ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

if __name__ == "__main__":
    main()
